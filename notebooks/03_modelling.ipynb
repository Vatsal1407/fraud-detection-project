{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fdb98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score,\n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "# Cross-validation\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Utilities\n",
    "import joblib\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FRAUD DETECTION - MODEL TRAINING\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n‚úì All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a4dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"LOADING PREPROCESSED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load the preprocessed data\n",
    "X_train_full = np.load('../data/preprocessed/X_train_full.npy')\n",
    "y_train_full = np.load('../data/preprocessed/y_train_full.npy')\n",
    "X_test = np.load('../data/preprocessed/X_test.npy')\n",
    "X_test_scaled = np.load('../data/preprocessed/X_test_scaled.npy')\n",
    "y_test = np.load('../data/preprocessed/y_test.npy')\n",
    "\n",
    "# Load preprocessing parameters\n",
    "params = joblib.load('../data/preprocessed/preprocessing_params.pkl')\n",
    "scaler = joblib.load('../data/preprocessed/scaler.pkl')\n",
    "\n",
    "# Load feature names\n",
    "with open('../data/preprocessed/feature_names.txt', 'r') as f:\n",
    "    feature_names = [line.strip() for line in f.readlines()]\n",
    "\n",
    "print(\"‚úì Data loaded successfully!\")\n",
    "print(f\"\\nTraining data shape: {X_train_full.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Number of features: {len(feature_names)}\")\n",
    "print(f\"\\nPreprocessing parameters:\")\n",
    "for key, value in params.items():\n",
    "    if key != 'feature_names':  # Skip feature names list (too long)\n",
    "        print(f\"  ‚Ä¢ {key}: {value}\")\n",
    "\n",
    "print(f\"\\nTraining set fraud distribution:\")\n",
    "print(f\"  Non-Fraud: {(y_train_full == 0).sum():,}\")\n",
    "print(f\"  Fraud: {(y_train_full == 1).sum():,}\")\n",
    "print(f\"  Fraud rate: {y_train_full.mean()*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nTest set fraud distribution:\")\n",
    "print(f\"  Non-Fraud: {(y_test == 0).sum():,}\")\n",
    "print(f\"  Fraud: {(y_test == 1).sum():,}\")\n",
    "print(f\"  Fraud rate: {y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa737632",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"K-FOLD CROSS-VALIDATION PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def evaluate_model_kfold_with_threshold(model, model_name, X, y, n_splits=5, \n",
    "                                         apply_smote=True, smote_strategy=0.5,\n",
    "                                         threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate model using Stratified K-Fold Cross-Validation with SMOTE and adjustable threshold\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : sklearn model\n",
    "        The model to evaluate\n",
    "    model_name : str\n",
    "        Name of the model for display\n",
    "    X : array\n",
    "        Feature matrix\n",
    "    y : array\n",
    "        Target vector\n",
    "    n_splits : int\n",
    "        Number of folds (default: 5)\n",
    "    apply_smote : bool\n",
    "        Whether to apply SMOTE (default: True)\n",
    "    smote_strategy : float\n",
    "        SMOTE sampling strategy (default: 0.5)\n",
    "    threshold : float\n",
    "        Decision threshold for classification (default: 0.5)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results : dict\n",
    "        Dictionary containing all metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TRAINING: {model_name} (Threshold: {threshold})\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_results = {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': [],\n",
    "        'roc_auc': []\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "        print(f\"\\nFold {fold_idx}/{n_splits}...\", end=\" \")\n",
    "        \n",
    "        # Split data\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Scale features\n",
    "        scaler_fold = StandardScaler()\n",
    "        X_train_fold_scaled = scaler_fold.fit_transform(X_train_fold)\n",
    "        X_val_fold_scaled = scaler_fold.transform(X_val_fold)\n",
    "        \n",
    "        # Apply SMOTE\n",
    "        if apply_smote:\n",
    "            smote = SMOTE(random_state=42, sampling_strategy=smote_strategy)\n",
    "            X_train_fold_scaled, y_train_fold = smote.fit_resample(X_train_fold_scaled, y_train_fold)\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train_fold_scaled, y_train_fold)\n",
    "        \n",
    "        # Predict probabilities\n",
    "        y_pred_proba = model.predict_proba(X_val_fold_scaled)[:, 1]\n",
    "        \n",
    "        # Apply custom threshold\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        fold_results['accuracy'].append(accuracy_score(y_val_fold, y_pred))\n",
    "        fold_results['precision'].append(precision_score(y_val_fold, y_pred, zero_division=0))\n",
    "        fold_results['recall'].append(recall_score(y_val_fold, y_pred, zero_division=0))\n",
    "        fold_results['f1'].append(f1_score(y_val_fold, y_pred, zero_division=0))\n",
    "        fold_results['roc_auc'].append(roc_auc_score(y_val_fold, y_pred_proba))\n",
    "        \n",
    "        print(f\"F1: {fold_results['f1'][-1]:.4f}, Recall: {fold_results['recall'][-1]:.4f}, Precision: {fold_results['precision'][-1]:.4f}\")\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RESULTS - {model_name} (Threshold: {threshold})\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Training time: {training_time:.2f} seconds\")\n",
    "    print(f\"\\nAverage Metrics (across {n_splits} folds):\")\n",
    "    print(f\"  Accuracy:  {np.mean(fold_results['accuracy']):.4f} ¬± {np.std(fold_results['accuracy']):.4f}\")\n",
    "    print(f\"  Precision: {np.mean(fold_results['precision']):.4f} ¬± {np.std(fold_results['precision']):.4f}\")\n",
    "    print(f\"  Recall:    {np.mean(fold_results['recall']):.4f} ¬± {np.std(fold_results['recall']):.4f}\")\n",
    "    print(f\"  F1-Score:  {np.mean(fold_results['f1']):.4f} ¬± {np.std(fold_results['f1']):.4f}\")\n",
    "    print(f\"  ROC-AUC:   {np.mean(fold_results['roc_auc']):.4f} ¬± {np.std(fold_results['roc_auc']):.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'threshold': threshold,\n",
    "        'fold_results': fold_results,\n",
    "        'avg_accuracy': np.mean(fold_results['accuracy']),\n",
    "        'avg_precision': np.mean(fold_results['precision']),\n",
    "        'avg_recall': np.mean(fold_results['recall']),\n",
    "        'avg_f1': np.mean(fold_results['f1']),\n",
    "        'avg_roc_auc': np.mean(fold_results['roc_auc']),\n",
    "        'training_time': training_time\n",
    "    }\n",
    "\n",
    "print(\"‚úì K-Fold CV pipeline function created with threshold adjustment!\")\n",
    "print(\"\\nThis function will:\")\n",
    "print(\"  1. Split data into K folds (stratified)\")\n",
    "print(\"  2. For each fold:\")\n",
    "print(\"     ‚Ä¢ Scale features\")\n",
    "print(\"     ‚Ä¢ Apply SMOTE (optional)\")\n",
    "print(\"     ‚Ä¢ Train model\")\n",
    "print(\"     ‚Ä¢ Evaluate with custom threshold\")\n",
    "print(\"  3. Return average metrics across all folds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1653f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MODEL 1: LOGISTIC REGRESSION (BASELINE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize Logistic Regression\n",
    "lr_model = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    class_weight=None,  # Handle class imbalance\n",
    "    n_jobs=-1  # Use all CPU cores\n",
    ")\n",
    "\n",
    "print(\"Model parameters:\")\n",
    "print(f\"  ‚Ä¢ max_iter: 1000\")\n",
    "print(f\"  ‚Ä¢ class_weight: balanced (helps with imbalanced data)\")\n",
    "print(f\"  ‚Ä¢ solver: lbfgs (default)\")\n",
    "\n",
    "# Train and evaluate using K-Fold CV\n",
    "lr_results = evaluate_model_kfold_with_threshold(\n",
    "    model=lr_model,\n",
    "    model_name=\"Logistic Regression\",\n",
    "    X=X_train_full,\n",
    "    y=y_train_full,\n",
    "    n_splits=5,\n",
    "    apply_smote=True,\n",
    "    smote_strategy=0.5\n",
    "    threshold=0.5\n",
    ")\n",
    "\n",
    "# Store results for later comparison\n",
    "all_results = [lr_results]\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"‚úì Logistic Regression training complete!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd580e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MODEL 1: LOGISTIC REGRESSION - COMPARING STRATEGIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# We'll test 3 strategies:\n",
    "# 1. SMOTE only\n",
    "# 2. Class weights only  \n",
    "# 3. Both (what we just did - for comparison)\n",
    "\n",
    "print(\"\\nWe'll compare 3 approaches to handling class imbalance:\")\n",
    "print(\"  Strategy 1: SMOTE only (no class_weight)\")\n",
    "print(\"  Strategy 2: Class weights only (no SMOTE)\")\n",
    "print(\"  Strategy 3: Both SMOTE + class_weight (our previous attempt)\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Strategy 1: SMOTE only\n",
    "print(\"\\nüîÑ STRATEGY 1: SMOTE ONLY\")\n",
    "lr_model_smote = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    class_weight=None,  # No class weights\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lr_results_smote = evaluate_model_kfold_with_threshold(\n",
    "    model=lr_model_smote,\n",
    "    model_name=\"Logistic Regression (SMOTE only)\",\n",
    "    X=X_train_full,\n",
    "    y=y_train_full,\n",
    "    n_splits=5,\n",
    "    apply_smote=True,\n",
    "    smote_strategy=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f50972",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîÑ STRATEGY 2: CLASS WEIGHTS ONLY (NO SMOTE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "lr_model_weights = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',  # Use class weights\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lr_results_weights = evaluate_model_kfold_with_threshold(\n",
    "    model=lr_model_weights,\n",
    "    model_name=\"Logistic Regression (Class weights only)\",\n",
    "    X=X_train_full,\n",
    "    y=y_train_full,\n",
    "    n_splits=5,\n",
    "    apply_smote=False,  # No SMOTE\n",
    "    smote_strategy=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d759583",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"LOGISTIC REGRESSION - STRATEGY COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Strategy': [\n",
    "        'SMOTE + Class Weights',\n",
    "        'SMOTE Only', \n",
    "        'Class Weights Only'\n",
    "    ],\n",
    "    'Recall': [0.4679, 0.0001, 0.4813],\n",
    "    'Precision': [0.0506, 0.0222, 0.0500],\n",
    "    'F1-Score': [0.0913, 0.0002, 0.0905],\n",
    "    'ROC-AUC': [0.5026, 0.5024, 0.4981],\n",
    "    'Training Time (s)': [9.20, 4.15, 2.17]\n",
    "})\n",
    "\n",
    "print(\"\\nComparison Table:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "strategies = comparison_df['Strategy']\n",
    "x_pos = np.arange(len(strategies))\n",
    "\n",
    "# Recall\n",
    "axes[0, 0].bar(x_pos, comparison_df['Recall'], color=['orange', 'red', 'green'], alpha=0.7)\n",
    "axes[0, 0].set_xticks(x_pos)\n",
    "axes[0, 0].set_xticklabels(strategies, rotation=15, ha='right')\n",
    "axes[0, 0].set_ylabel('Recall')\n",
    "axes[0, 0].set_title('Recall Comparison')\n",
    "axes[0, 0].set_ylim(0, 1)\n",
    "axes[0, 0].axhline(y=0.85, color='gray', linestyle='--', label='Target (85%)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# F1-Score\n",
    "axes[0, 1].bar(x_pos, comparison_df['F1-Score'], color=['orange', 'red', 'green'], alpha=0.7)\n",
    "axes[0, 1].set_xticks(x_pos)\n",
    "axes[0, 1].set_xticklabels(strategies, rotation=15, ha='right')\n",
    "axes[0, 1].set_ylabel('F1-Score')\n",
    "axes[0, 1].set_title('F1-Score Comparison')\n",
    "axes[0, 1].set_ylim(0, 1)\n",
    "axes[0, 1].axhline(y=0.82, color='gray', linestyle='--', label='Target (82%)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# ROC-AUC\n",
    "axes[1, 0].bar(x_pos, comparison_df['ROC-AUC'], color=['orange', 'red', 'green'], alpha=0.7)\n",
    "axes[1, 0].set_xticks(x_pos)\n",
    "axes[1, 0].set_xticklabels(strategies, rotation=15, ha='right')\n",
    "axes[1, 0].set_ylabel('ROC-AUC')\n",
    "axes[1, 0].set_title('ROC-AUC Comparison')\n",
    "axes[1, 0].set_ylim(0, 1)\n",
    "axes[1, 0].axhline(y=0.90, color='gray', linestyle='--', label='Target (90%)')\n",
    "axes[1, 0].axhline(y=0.50, color='red', linestyle='--', label='Random Guess')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Training Time\n",
    "axes[1, 1].bar(x_pos, comparison_df['Training Time (s)'], color=['orange', 'red', 'green'], alpha=0.7)\n",
    "axes[1, 1].set_xticks(x_pos)\n",
    "axes[1, 1].set_xticklabels(strategies, rotation=15, ha='right')\n",
    "axes[1, 1].set_ylabel('Training Time (seconds)')\n",
    "axes[1, 1].set_title('Training Time Comparison')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCLUSION:\")\n",
    "print(\"=\"*80)\n",
    "print(\"‚úì Best strategy for Logistic Regression: Class Weights Only\")\n",
    "print(\"  ‚Ä¢ Similar performance to SMOTE + Class Weights\")\n",
    "print(\"  ‚Ä¢ 4x faster training time\")\n",
    "print(\"  ‚Ä¢ Simpler implementation\")\n",
    "print(\"\\n‚ö†Ô∏è However, Logistic Regression overall performance is POOR:\")\n",
    "print(f\"  ‚Ä¢ Recall: ~48% (target: 85%+)\")\n",
    "print(f\"  ‚Ä¢ F1-Score: ~9% (target: 82%+)\")\n",
    "print(f\"  ‚Ä¢ ROC-AUC: ~0.50 (target: 0.90+, currently random guessing)\")\n",
    "print(\"\\nüöÄ Next: Train Random Forest - should perform MUCH better!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MODEL 2: RANDOM FOREST CLASSIFIER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize Random Forest\n",
    "# Based on our Logistic Regression findings, we'll use class_weight='balanced' (not SMOTE)\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,           # Number of trees\n",
    "    max_depth=20,               # Limit depth to prevent overfitting\n",
    "    min_samples_split=10,       # Minimum samples to split a node\n",
    "    min_samples_leaf=5,         # Minimum samples in leaf node\n",
    "    class_weight='balanced',    # Handle imbalance\n",
    "    random_state=42,\n",
    "    n_jobs=-1,                  # Use all CPU cores\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"Model parameters:\")\n",
    "print(f\"  ‚Ä¢ n_estimators: 100 (number of trees)\")\n",
    "print(f\"  ‚Ä¢ max_depth: 20 (prevent overfitting)\")\n",
    "print(f\"  ‚Ä¢ min_samples_split: 10\")\n",
    "print(f\"  ‚Ä¢ min_samples_leaf: 5\")\n",
    "print(f\"  ‚Ä¢ class_weight: balanced (no SMOTE)\")\n",
    "print(f\"  ‚Ä¢ Using all CPU cores for faster training\")\n",
    "\n",
    "print(\"\\nTraining Random Forest with K-Fold CV...\")\n",
    "print(\"(This may take 2-5 minutes depending on your CPU)\")\n",
    "\n",
    "# Train and evaluate using K-Fold CV (without SMOTE based on our findings)\n",
    "rf_results = evaluate_model_kfold_with_threshold(\n",
    "    model=rf_model,\n",
    "    model_name=\"Random Forest\",\n",
    "    X=X_train_full,\n",
    "    y=y_train_full,\n",
    "    n_splits=5,\n",
    "    apply_smote=False,  # No SMOTE - class weights work better\n",
    "    smote_strategy=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db23c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MODEL 2: RANDOM FOREST (RETRY WITH SMOTE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Random Forest WITHOUT class_weight, but WITH SMOTE\n",
    "rf_model_smote = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight=None,  # No class weight - let SMOTE handle it\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"Model parameters:\")\n",
    "print(f\"  ‚Ä¢ n_estimators: 100\")\n",
    "print(f\"  ‚Ä¢ max_depth: 20\")\n",
    "print(f\"  ‚Ä¢ class_weight: None (using SMOTE instead)\")\n",
    "\n",
    "print(\"\\nTraining Random Forest with SMOTE...\")\n",
    "\n",
    "# Train with SMOTE\n",
    "rf_results_smote = evaluate_model_kfold_with_threshold(\n",
    "    model=rf_model_smote,\n",
    "    model_name=\"Random Forest (with SMOTE)\",\n",
    "    X=X_train_full,\n",
    "    y=y_train_full,\n",
    "    n_splits=5,\n",
    "    apply_smote=True,  # Use SMOTE\n",
    "    smote_strategy=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e4d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DEBUGGING - CHECK MODEL PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Let's manually test one fold to see what's happening\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "train_idx, val_idx = list(skf.split(X_train_full, y_train_full))[0]\n",
    "\n",
    "# Get one fold\n",
    "X_train_fold = X_train_full[train_idx]\n",
    "X_val_fold = X_train_full[val_idx]\n",
    "y_train_fold = y_train_full[train_idx]\n",
    "y_val_fold = y_train_full[val_idx]\n",
    "\n",
    "print(f\"Fold 1 - Training samples: {len(y_train_fold):,}\")\n",
    "print(f\"Fold 1 - Validation samples: {len(y_val_fold):,}\")\n",
    "print(f\"\\nTraining fraud distribution:\")\n",
    "print(f\"  Non-Fraud: {(y_train_fold == 0).sum():,}\")\n",
    "print(f\"  Fraud: {(y_train_fold == 1).sum():,}\")\n",
    "\n",
    "# Scale\n",
    "scaler_test = StandardScaler()\n",
    "X_train_scaled = scaler_test.fit_transform(X_train_fold)\n",
    "X_val_scaled = scaler_test.transform(X_val_fold)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote_test = SMOTE(random_state=42, sampling_strategy=0.5)\n",
    "X_train_smote, y_train_smote = smote_test.fit_resample(X_train_scaled, y_train_fold)\n",
    "\n",
    "print(f\"\\nAfter SMOTE:\")\n",
    "print(f\"  Training samples: {len(y_train_smote):,}\")\n",
    "print(f\"  Non-Fraud: {(y_train_smote == 0).sum():,}\")\n",
    "print(f\"  Fraud: {(y_train_smote == 1).sum():,}\")\n",
    "\n",
    "# Train a simple Random Forest\n",
    "rf_test = RandomForestClassifier(n_estimators=10, random_state=42, n_jobs=-1)\n",
    "rf_test.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict\n",
    "y_pred = rf_test.predict(X_val_scaled)\n",
    "\n",
    "print(f\"\\nPredictions on validation set:\")\n",
    "print(f\"  Predicted Non-Fraud: {(y_pred == 0).sum():,}\")\n",
    "print(f\"  Predicted Fraud: {(y_pred == 1).sum():,}\")\n",
    "\n",
    "print(f\"\\nActual validation set:\")\n",
    "print(f\"  Actual Non-Fraud: {(y_val_fold == 0).sum():,}\")\n",
    "print(f\"  Actual Fraud: {(y_val_fold == 1).sum():,}\")\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val_fold, y_pred))\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_val_fold, y_pred, target_names=['Non-Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae523aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RANDOM FOREST WITH THRESHOLD 0.3\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rf_model_threshold = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train with threshold=0.3 (more aggressive fraud detection)\n",
    "rf_results_t03 = evaluate_model_kfold_with_threshold(\n",
    "    model=rf_model_threshold,\n",
    "    model_name=\"Random Forest\",\n",
    "    X=X_train_full,\n",
    "    y=y_train_full,\n",
    "    n_splits=5,\n",
    "    apply_smote=True,\n",
    "    smote_strategy=0.5,\n",
    "    threshold=0.3  # Lower threshold = catch more fraud\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82db2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RANDOM FOREST WITH THRESHOLD 0.1\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rf_model_threshold = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train with threshold=0.1 (even more aggressive fraud detection)\n",
    "rf_results_t01 = evaluate_model_kfold_with_threshold(\n",
    "    model=rf_model_threshold,\n",
    "    model_name=\"Random Forest\",\n",
    "    X=X_train_full,\n",
    "    y=y_train_full,\n",
    "    n_splits=5,\n",
    "    apply_smote=True,\n",
    "    smote_strategy=0.5,\n",
    "    threshold=0.1  # Lower threshold = catch more fraud\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddf46c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RANDOM FOREST WITH THRESHOLD 0.01\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rf_model_threshold = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train with threshold=0.01 (most aggressive fraud detection)\n",
    "rf_results_t001 = evaluate_model_kfold_with_threshold(\n",
    "    model=rf_model_threshold,\n",
    "    model_name=\"Random Forest\",\n",
    "    X=X_train_full,\n",
    "    y=y_train_full,\n",
    "    n_splits=5,\n",
    "    apply_smote=True,\n",
    "    smote_strategy=0.5,\n",
    "    threshold=0.01  # Lower threshold = catch more fraud\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d86b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DEEP DEBUGGING - CHECK PROBABILITY DISTRIBUTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Let's see what probabilities the model is actually outputting\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "train_idx, val_idx = list(skf.split(X_train_full, y_train_full))[0]\n",
    "\n",
    "X_train_fold = X_train_full[train_idx]\n",
    "X_val_fold = X_train_full[val_idx]\n",
    "y_train_fold = y_train_full[train_idx]\n",
    "y_val_fold = y_train_full[val_idx]\n",
    "\n",
    "# Scale\n",
    "scaler_test = StandardScaler()\n",
    "X_train_scaled = scaler_test.fit_transform(X_train_fold)\n",
    "X_val_scaled = scaler_test.transform(X_val_fold)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote_test = SMOTE(random_state=42, sampling_strategy=0.5)\n",
    "X_train_smote, y_train_smote = smote_test.fit_resample(X_train_scaled, y_train_fold)\n",
    "\n",
    "print(f\"After SMOTE - Training set:\")\n",
    "print(f\"  Fraud: {(y_train_smote == 1).sum():,} ({(y_train_smote == 1).mean()*100:.1f}%)\")\n",
    "print(f\"  Non-Fraud: {(y_train_smote == 0).sum():,} ({(y_train_smote == 0).mean()*100:.1f}%)\")\n",
    "\n",
    "# Train Random Forest\n",
    "rf_debug = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_debug.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Get probabilities\n",
    "y_pred_proba = rf_debug.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PROBABILITY DISTRIBUTION ON VALIDATION SET:\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\nProbability Statistics:\")\n",
    "print(f\"  Min: {y_pred_proba.min():.6f}\")\n",
    "print(f\"  Max: {y_pred_proba.max():.6f}\")\n",
    "print(f\"  Mean: {y_pred_proba.mean():.6f}\")\n",
    "print(f\"  Median: {np.median(y_pred_proba):.6f}\")\n",
    "print(f\"  Std: {y_pred_proba.std():.6f}\")\n",
    "\n",
    "print(f\"\\nProbability ranges:\")\n",
    "print(f\"  0.0 - 0.1: {(y_pred_proba < 0.1).sum():,} samples ({(y_pred_proba < 0.1).mean()*100:.1f}%)\")\n",
    "print(f\"  0.1 - 0.2: {((y_pred_proba >= 0.1) & (y_pred_proba < 0.2)).sum():,} samples\")\n",
    "print(f\"  0.2 - 0.3: {((y_pred_proba >= 0.2) & (y_pred_proba < 0.3)).sum():,} samples\")\n",
    "print(f\"  0.3 - 0.4: {((y_pred_proba >= 0.3) & (y_pred_proba < 0.4)).sum():,} samples\")\n",
    "print(f\"  0.4 - 0.5: {((y_pred_proba >= 0.4) & (y_pred_proba < 0.5)).sum():,} samples\")\n",
    "print(f\"  0.5 - 1.0: {(y_pred_proba >= 0.5).sum():,} samples\")\n",
    "\n",
    "# Check probabilities for actual fraud vs non-fraud\n",
    "fraud_probas = y_pred_proba[y_val_fold == 1]\n",
    "non_fraud_probas = y_pred_proba[y_val_fold == 0]\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PROBABILITIES FOR ACTUAL FRAUD vs NON-FRAUD:\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\nActual FRAUD cases (n={len(fraud_probas):,}):\")\n",
    "print(f\"  Mean probability: {fraud_probas.mean():.6f}\")\n",
    "print(f\"  Max probability: {fraud_probas.max():.6f}\")\n",
    "print(f\"  Min probability: {fraud_probas.min():.6f}\")\n",
    "print(f\"  Above 0.3: {(fraud_probas >= 0.3).sum():,} ({(fraud_probas >= 0.3).mean()*100:.1f}%)\")\n",
    "print(f\"  Above 0.5: {(fraud_probas >= 0.5).sum():,} ({(fraud_probas >= 0.5).mean()*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nActual NON-FRAUD cases (n={len(non_fraud_probas):,}):\")\n",
    "print(f\"  Mean probability: {non_fraud_probas.mean():.6f}\")\n",
    "print(f\"  Max probability: {non_fraud_probas.max():.6f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(fraud_probas, bins=50, alpha=0.7, color='red', label='Actual Fraud', edgecolor='black')\n",
    "axes[0].axvline(x=0.3, color='blue', linestyle='--', label='Threshold 0.3')\n",
    "axes[0].axvline(x=0.5, color='green', linestyle='--', label='Threshold 0.5')\n",
    "axes[0].set_xlabel('Predicted Fraud Probability')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Probability Distribution for ACTUAL FRAUD Cases')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].hist(non_fraud_probas, bins=50, alpha=0.7, color='green', label='Actual Non-Fraud', edgecolor='black')\n",
    "axes[1].axvline(x=0.3, color='blue', linestyle='--', label='Threshold 0.3')\n",
    "axes[1].axvline(x=0.5, color='green', linestyle='--', label='Threshold 0.5')\n",
    "axes[1].set_xlabel('Predicted Fraud Probability')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Probability Distribution for ACTUAL NON-FRAUD Cases')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808f7068",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MODEL 3: XGBOOST WITH THRESHOLD 0.1\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_results = evaluate_model_kfold_with_threshold(\n",
    "    model=xgb_model,\n",
    "    model_name=\"XGBoost\",\n",
    "    X=X_train_full,\n",
    "    y=y_train_full,\n",
    "    n_splits=5,\n",
    "    apply_smote=True,\n",
    "    smote_strategy=0.5,\n",
    "    threshold=0.1  # Balanced threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18901c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PROJECT SUMMARY - MODEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Build comparison table from actual results objects\n",
    "all_models_comparison = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'Logistic Regression (Class Weights)',\n",
    "        'Logistic Regression (SMOTE only)',\n",
    "        'Logistic Regression (Class Weights only)',\n",
    "        'Random Forest (T=0.3)',\n",
    "        'Random Forest (T=0.1)',\n",
    "        'Random Forest (T=0.01)',\n",
    "        'XGBoost (T=0.1)'\n",
    "    ],\n",
    "    'Strategy': [\n",
    "        'Class Weights + SMOTE',\n",
    "        'SMOTE',\n",
    "        'Class Weights',\n",
    "        'SMOTE',\n",
    "        'SMOTE',\n",
    "        'SMOTE',\n",
    "        'SMOTE'\n",
    "    ],\n",
    "    'Threshold': [\n",
    "        'default',\n",
    "        'default',\n",
    "        'default',\n",
    "        '0.3',\n",
    "        '0.1',\n",
    "        '0.01',\n",
    "        '0.1'\n",
    "    ],\n",
    "    'Recall': [\n",
    "        lr_results['avg_recall'],\n",
    "        lr_results_smote['avg_recall'],\n",
    "        lr_results_weights['avg_recall'],\n",
    "        rf_results_t03['avg_recall'],\n",
    "        rf_results_t01['avg_recall'],\n",
    "        rf_results_t001['avg_recall'],\n",
    "        xgb_results['avg_recall']\n",
    "    ],\n",
    "    'Precision': [\n",
    "        lr_results['avg_precision'],\n",
    "        lr_results_smote['avg_precision'],\n",
    "        lr_results_weights['avg_precision'],\n",
    "        rf_results_t03['avg_precision'],\n",
    "        rf_results_t01['avg_precision'],\n",
    "        rf_results_t001['avg_precision'],\n",
    "        xgb_results['avg_precision']\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        lr_results['avg_f1'],\n",
    "        lr_results_smote['avg_f1'],\n",
    "        lr_results_weights['avg_f1'],\n",
    "        rf_results_t03['avg_f1'],\n",
    "        rf_results_t01['avg_f1'],\n",
    "        rf_results_t001['avg_f1'],\n",
    "        xgb_results['avg_f1']\n",
    "    ],\n",
    "    'ROC-AUC': [\n",
    "        lr_results['avg_roc_auc'],\n",
    "        lr_results_smote['avg_roc_auc'],\n",
    "        lr_results_weights['avg_roc_auc'],\n",
    "        rf_results_t03['avg_roc_auc'],\n",
    "        rf_results_t01['avg_roc_auc'],\n",
    "        rf_results_t001['avg_roc_auc'],\n",
    "        xgb_results['avg_roc_auc']\n",
    "    ],\n",
    "    'Training Time (s)': [\n",
    "        lr_results['training_time'],\n",
    "        lr_results_smote['training_time'],\n",
    "        lr_results_weights['training_time'],\n",
    "        rf_results_t03['training_time'],\n",
    "        rf_results_t01['training_time'],\n",
    "        rf_results_t001['training_time'],\n",
    "        xgb_results['training_time']\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nAll Models Comparison:\")\n",
    "print(all_models_comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n1. DATA QUALITY ISSUE:\")\n",
    "print(\"   ‚úó All models achieve ROC-AUC ‚âà 0.50 (random guessing)\")\n",
    "print(\"   ‚úó Dataset features cannot distinguish fraud from non-fraud\")\n",
    "print(\"   ‚úó Confirmed through probability distribution analysis\")\n",
    "\n",
    "print(\"\\n2. METHODOLOGY SUCCESS:\")\n",
    "print(\"   ‚úì Proper K-Fold CV implementation\")\n",
    "print(\"   ‚úì Tested multiple imbalance handling strategies\")\n",
    "print(\"   ‚úì Systematic threshold optimization\")\n",
    "print(\"   ‚úì Comprehensive model comparison\")\n",
    "\n",
    "print(\"\\n3. BEST MODEL SELECTION:\")\n",
    "print(\"   ‚Ä¢ Random Forest with threshold 0.1 (best F1-score balance)\")\n",
    "print(f\"   ‚Ä¢ Recall: ~50% | Precision: ~5% | F1: ~10%\")\n",
    "print(\"   ‚Ä¢ Better than predicting all fraud (T=0.01) or all non-fraud (T=0.5)\")\n",
    "\n",
    "print(\"\\n4. ROOT CAUSE:\")\n",
    "print(\"   ‚Ä¢ EDA showed weak features (all ~5% fraud rate)\")\n",
    "print(\"   ‚Ä¢ Model probability analysis confirmed lack of separation\")\n",
    "print(\"   ‚Ä¢ Max fraud probability: 0.37 (never reaches 0.5)\")\n",
    "print(\"   ‚Ä¢ Fraud and non-fraud probability distributions overlap completely\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDATION:\")\n",
    "print(\"=\"*80)\n",
    "print(\"Deploy Random Forest (T=0.1) as 'best effort' model with caveats:\")\n",
    "print(\"  ‚Ä¢ Model performance limited by data quality\")\n",
    "print(\"  ‚Ä¢ Requires better features or external data sources\")\n",
    "print(\"  ‚Ä¢ Current model suitable for flagging potential fraud for review\")\n",
    "print(\"  ‚Ä¢ NOT suitable for automatic fraud blocking\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c369f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TRAINING FINAL MODEL ON FULL TRAINING DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Train Random Forest on ALL training data (not just folds)\n",
    "print(\"\\nTraining Random Forest on full training set (160,000 samples)...\")\n",
    "\n",
    "# Scale the full training data\n",
    "scaler_final = StandardScaler()\n",
    "X_train_full_scaled = scaler_final.fit_transform(X_train_full)\n",
    "\n",
    "# Apply SMOTE to full training data\n",
    "smote_final = SMOTE(random_state=42, sampling_strategy=0.5)\n",
    "X_train_smote_final, y_train_smote_final = smote_final.fit_resample(X_train_full_scaled, y_train_full)\n",
    "\n",
    "print(f\"After SMOTE:\")\n",
    "print(f\"  Training samples: {len(y_train_smote_final):,}\")\n",
    "print(f\"  Fraud: {(y_train_smote_final == 1).sum():,} ({(y_train_smote_final == 1).mean()*100:.1f}%)\")\n",
    "print(f\"  Non-Fraud: {(y_train_smote_final == 0).sum():,} ({(y_train_smote_final == 0).mean()*100:.1f}%)\")\n",
    "\n",
    "# Train final model\n",
    "final_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining...\")\n",
    "final_model.fit(X_train_smote_final, y_train_smote_final)\n",
    "print(\"‚úì Training complete!\")\n",
    "\n",
    "# Evaluate on hold-out test set\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATION ON HOLD-OUT TEST SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Scale test set\n",
    "X_test_scaled_final = scaler_final.transform(X_test)\n",
    "\n",
    "# Predict with threshold 0.1\n",
    "y_test_proba = final_model.predict_proba(X_test_scaled_final)[:, 1]\n",
    "y_test_pred = (y_test_proba >= 0.1).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred, zero_division=0)\n",
    "test_recall = recall_score(y_test, y_test_pred, zero_division=0)\n",
    "test_f1 = f1_score(y_test, y_test_pred, zero_division=0)\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(f\"\\nFinal Model Performance (Threshold = 0.1):\")\n",
    "print(f\"  Accuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"  Precision: {test_precision:.4f}\")\n",
    "print(f\"  Recall:    {test_recall:.4f}\")\n",
    "print(f\"  F1-Score:  {test_f1:.4f}\")\n",
    "print(f\"  ROC-AUC:   {test_roc_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(cm)\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Non-Fraud', 'Fraud']))\n",
    "\n",
    "# Save the final model\n",
    "import os\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "joblib.dump(final_model, '../models/random_forest_fraud_detector.pkl')\n",
    "joblib.dump(scaler_final, '../models/scaler_final.pkl')\n",
    "\n",
    "# Save model metadata\n",
    "model_metadata = {\n",
    "    'model_name': 'Random Forest Fraud Detector',\n",
    "    'threshold': 0.1,\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 20,\n",
    "    'training_samples': len(y_train_smote_final),\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'test_precision': test_precision,\n",
    "    'test_recall': test_recall,\n",
    "    'test_f1': test_f1,\n",
    "    'test_roc_auc': test_roc_auc,\n",
    "    'feature_names': feature_names\n",
    "}\n",
    "joblib.dump(model_metadata, '../models/model_metadata.pkl')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì Model saved successfully!\")\n",
    "print(\"=\"*80)\n",
    "print(\"Saved files:\")\n",
    "print(\"  ‚Ä¢ ../models/random_forest_fraud_detector.pkl\")\n",
    "print(\"  ‚Ä¢ ../models/scaler_final.pkl\")\n",
    "print(\"  ‚Ä¢ ../models/model_metadata.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a065eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CREATING FINAL VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Model Comparison - F1 Scores\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "models = ['LR', 'RF\\n(T=0.5)', 'RF\\n(T=0.3)', 'RF\\n(T=0.1)', 'RF\\n(T=0.01)', 'XGB\\n(T=0.1)']\n",
    "f1_scores = [0.0905, 0.0007, 0.0007, 0.10, 0.0960, 0.0530]\n",
    "colors = ['blue', 'red', 'red', 'green', 'orange', 'purple']\n",
    "ax1.bar(models, f1_scores, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax1.set_ylabel('F1-Score', fontsize=12)\n",
    "ax1.set_title('Model Comparison - F1-Score', fontsize=14, fontweight='bold')\n",
    "ax1.axhline(y=0.82, color='gray', linestyle='--', linewidth=2, label='Target (82%)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Model Comparison - ROC-AUC\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "roc_aucs = [0.4981, 0.5035, 0.5035, 0.50, 0.5035, 0.4993]\n",
    "ax2.bar(models, roc_aucs, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax2.set_ylabel('ROC-AUC', fontsize=12)\n",
    "ax2.set_title('Model Comparison - ROC-AUC', fontsize=14, fontweight='bold')\n",
    "ax2.axhline(y=0.90, color='gray', linestyle='--', linewidth=2, label='Target (90%)')\n",
    "ax2.axhline(y=0.50, color='red', linestyle='--', linewidth=2, label='Random Guess')\n",
    "ax2.set_ylim(0.4, 1.0)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Confusion Matrix - Test Set\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True, ax=ax3,\n",
    "            xticklabels=['Predicted\\nNon-Fraud', 'Predicted\\nFraud'],\n",
    "            yticklabels=['Actual\\nNon-Fraud', 'Actual\\nFraud'])\n",
    "ax3.set_title('Confusion Matrix - Hold-out Test Set', fontsize=14, fontweight='bold')\n",
    "ax3.set_ylabel('Actual', fontsize=12)\n",
    "ax3.set_xlabel('Predicted', fontsize=12)\n",
    "\n",
    "# 4. Precision-Recall Trade-off\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "thresholds_test = [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "precisions_test = []\n",
    "recalls_test = []\n",
    "\n",
    "for thresh in thresholds_test:\n",
    "    y_pred_thresh = (y_test_proba >= thresh).astype(int)\n",
    "    precisions_test.append(precision_score(y_test, y_pred_thresh, zero_division=0))\n",
    "    recalls_test.append(recall_score(y_test, y_pred_thresh, zero_division=0))\n",
    "\n",
    "ax4.plot(recalls_test, precisions_test, 'b-o', linewidth=2, markersize=8, label='Test Set')\n",
    "ax4.scatter([test_recall], [test_precision], color='red', s=200, marker='*', \n",
    "            label=f'Selected Model (T=0.1)', zorder=5, edgecolors='black', linewidths=2)\n",
    "ax4.set_xlabel('Recall', fontsize=12)\n",
    "ax4.set_ylabel('Precision', fontsize=12)\n",
    "ax4.set_title('Precision-Recall Trade-off', fontsize=14, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.legend()\n",
    "ax4.set_xlim(0, 1)\n",
    "ax4.set_ylim(0, 0.15)\n",
    "\n",
    "# 5. Feature Importance (Top 15)\n",
    "ax5 = fig.add_subplot(gs[2, :])\n",
    "feature_importances = final_model.feature_importances_\n",
    "indices = np.argsort(feature_importances)[-15:]  # Top 15\n",
    "top_features = [feature_names[i] for i in indices]\n",
    "top_importances = feature_importances[indices]\n",
    "\n",
    "ax5.barh(top_features, top_importances, color='teal', alpha=0.7, edgecolor='black')\n",
    "ax5.set_xlabel('Feature Importance', fontsize=12)\n",
    "ax5.set_title('Top 15 Most Important Features', fontsize=14, fontweight='bold')\n",
    "ax5.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.suptitle('Fraud Detection Model - Final Analysis', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.savefig('../models/model_evaluation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Visualization saved: ../models/model_evaluation.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
